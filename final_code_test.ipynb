{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ef083cc-9fbb-497a-983d-c3efdacf1606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catalog path: C:\\Users\\dipes\\Siesmic_model_NASA\\data\\lunar\\training\\catalogs\\apollo12_catalog_GradeA_final.csv\n",
      "Data directory: C:\\Users\\dipes\\Siesmic_model_NASA\\data\\lunar\\training\\data\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1970-01-19HR00_evid00002.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1970-03-25HR00_evid00003.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1970-03-26HR00_evid00004.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1970-04-25HR00_evid00006.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1970-04-26HR00_evid00007.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1970-06-15HR00_evid00008.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1970-06-26HR00_evid00009.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1970-07-20HR00_evid00010.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1970-07-20HR00_evid00011.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1970-09-26HR00_evid00013.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1970-10-24HR00_evid00014.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1970-11-12HR00_evid00015.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1970-12-11HR00_evid00017.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1970-12-27HR00_evid00019.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1970-12-31HR00_evid00021.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1971-01-15HR00_evid00022.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1971-01-28HR00_evid00023.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1971-01-29HR00_evid00024.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1971-02-09HR00_evid00026.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1971-03-25HR00_evid00028.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1971-04-13HR00_evid00029.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1971-04-17HR00_evid00030.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1971-05-12HR00_evid00031.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1971-05-12HR00_evid00032.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1971-05-13HR00_evid00033.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1971-05-23HR00_evid00034.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1971-06-12HR00_evid00035.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1971-09-25HR00_evid00042.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1971-10-18HR00_evid00043.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1971-10-20HR00_evid00044.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1971-10-31HR00_evid00045.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1971-11-14HR00_evid00046.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1972-01-04HR00_evid00049.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1972-03-12HR00_evid00052.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1972-05-11HR00_evid00055.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1972-06-16HR00_evid00060.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1972-07-17HR00_evid00067.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1972-07-17HR00_evid00068.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1972-07-28HR00_evid00070.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1972-07-31HR00_evid00071.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1972-12-02HR00_evid00083.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1972-12-03HR00_evid00084.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1973-01-18HR00_evid00088.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1973-01-31HR00_evid00091.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1973-03-01HR00_evid00093.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1973-03-13HR00_evid00094.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1973-03-24HR00_evid00097.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1973-05-14HR00_evid00104.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1973-06-05HR00_evid00107.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1973-06-05HR00_evid00108.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1973-06-18HR00_evid00109.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1973-06-27HR00_evid00112.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1973-07-03HR00_evid00113.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1973-07-04HR00_evid00114.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1973-07-20HR00_evid00117.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1973-07-28HR00_evid00120.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1973-07-29HR00_evid00121.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1973-08-21HR00_evid00127.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1974-01-10HR00_evid00136.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1974-02-07HR00_evid00137.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1974-02-12HR00_evid00138.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1974-03-25HR00_evid00140.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1974-04-08HR00_evid00141.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1974-04-19HR00_evid00142.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1974-04-26HR00_evid00144.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1974-04-27HR00_evid00145.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1974-06-25HR00_evid00149.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1974-07-06HR00_evid00150.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1974-07-06HR00_evid00151.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1974-07-11HR00_evid00152.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1974-07-17HR00_evid00153.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1974-10-14HR00_evid00156.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1975-04-12HR00_evid00191.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1975-05-04HR00_evid00192.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1975-06-24HR00_evid00196.mseed\n",
      "File not found: ./data/lunar/training/data/xa.s12.00.mhz.1975-06-26HR00_evid00198.mseed\n",
      "No data was successfully loaded. Please check your file paths and data.\n",
      "Training failed. Please check your data and file paths.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from obspy import read\n",
    "from obspy.signal.trigger import trigger_onset\n",
    "import joblib\n",
    "\n",
    "# Load the catalog\n",
    "def load_catalog(catalog_path):\n",
    "    catalog = pd.read_csv(catalog_path)\n",
    "    catalog['time_abs'] = pd.to_datetime(catalog['time_abs(%Y-%m-%dT%H:%M:%S.%f)'])\n",
    "    return catalog\n",
    "\n",
    "# Load a single MSEED file\n",
    "def load_mseed_file(file_path):\n",
    "    try:\n",
    "        stream = read(file_path)\n",
    "        trace = stream[0]\n",
    "        \n",
    "        data = pd.DataFrame({\n",
    "            'time_rel(sec)': trace.times(),\n",
    "            'velocity': trace.data,\n",
    "        })\n",
    "        \n",
    "        data['time_abs'] = pd.to_datetime(trace.stats.starttime.datetime) + pd.to_timedelta(data['time_rel(sec)'], unit='s')\n",
    "        \n",
    "        return data, trace.stats.sampling_rate\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading file {file_path}: {str(e)}\")\n",
    "        return None, None\n",
    "\n",
    "# Feature engineering\n",
    "def engineer_features(data, sampling_rate):\n",
    "    window_size = int(sampling_rate * 15)  # 15 seconds window\n",
    "    data['velocity_rolling_mean'] = data['velocity'].rolling(window=window_size).mean()\n",
    "    data['velocity_rolling_std'] = data['velocity'].rolling(window=window_size).std()\n",
    "    \n",
    "    f, t, Sxx = signal.spectrogram(data['velocity'], fs=sampling_rate)\n",
    "    spectral_mean = np.mean(Sxx, axis=0)\n",
    "    spectral_std = np.std(Sxx, axis=0)\n",
    "    \n",
    "    data['spectral_mean'] = np.interp(data['time_rel(sec)'], t, spectral_mean)\n",
    "    data['spectral_std'] = np.interp(data['time_rel(sec)'], t, spectral_std)\n",
    "    \n",
    "    sta_window = int(sampling_rate * 120)  # 2 minutes\n",
    "    lta_window = int(sampling_rate * 600)  # 10 minutes\n",
    "    data['sta'] = data['velocity'].abs().rolling(window=sta_window).mean()\n",
    "    data['lta'] = data['velocity'].abs().rolling(window=lta_window).mean()\n",
    "    data['sta_lta_ratio'] = data['sta'] / data['lta']\n",
    "    \n",
    "    # Add trigger on/off feature\n",
    "    cft = data['sta_lta_ratio'].fillna(0)\n",
    "    thr_on, thr_off = 4, 1.5\n",
    "    on_off = trigger_onset(cft, thr_on, thr_off)\n",
    "    data['trigger'] = 0\n",
    "    for start, end in on_off:\n",
    "        data.loc[start:end, 'trigger'] = 1\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Train Isolation Forest model\n",
    "def train_isolation_forest(data):\n",
    "    features = ['velocity', 'velocity_rolling_mean', 'velocity_rolling_std', 'spectral_mean', 'spectral_std', 'sta_lta_ratio', 'trigger']\n",
    "    X = data[features].dropna()\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    clf = IsolationForest(contamination=0.01, random_state=42)\n",
    "    clf.fit(X_scaled)\n",
    "    \n",
    "    return clf, scaler\n",
    "\n",
    "# Train ARIMA model\n",
    "def train_arima(data):\n",
    "    model = ARIMA(data['velocity'], order=(5,1,0))\n",
    "    results = model.fit()\n",
    "    return results\n",
    "\n",
    "# Main training function\n",
    "def train_models(catalog_path, data_directory):\n",
    "    catalog = load_catalog(catalog_path)\n",
    "    all_data = pd.DataFrame()\n",
    "    \n",
    "    for _, row in catalog.iterrows():\n",
    "        file_name = row['filename']\n",
    "        file_path = os.path.join(data_directory, file_name + '.mseed').replace(\"\\\\\",\"/\")\n",
    "        \n",
    "        if os.path.exists(file_path):\n",
    "            data, sampling_rate = load_mseed_file(file_path)\n",
    "            if data is not None and sampling_rate is not None:\n",
    "                data = engineer_features(data, sampling_rate)\n",
    "                all_data = pd.concat([all_data, data])\n",
    "        else:\n",
    "            print(f\"File not found: {file_path}\")\n",
    "    \n",
    "    if all_data.empty:\n",
    "        print(\"No data was successfully loaded. Please check your file paths and data.\")\n",
    "        return None, None, None, None\n",
    "    \n",
    "    isolation_forest, scaler = train_isolation_forest(all_data)\n",
    "    arima_model = train_arima(all_data)\n",
    "    \n",
    "    return isolation_forest, scaler, arima_model, all_data\n",
    "\n",
    "# Plot training data\n",
    "def plot_training_data(training_data):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.subplot(4, 1, 1)\n",
    "    plt.plot(training_data['time_rel(sec)'], training_data['velocity'])\n",
    "    plt.title('Velocity')\n",
    "    plt.subplot(4, 1, 2)\n",
    "    plt.plot(training_data['time_rel(sec)'], training_data['sta_lta_ratio'])\n",
    "    plt.title('STA/LTA Ratio')\n",
    "    plt.subplot(4, 1, 3)\n",
    "    plt.plot(training_data['time_rel(sec)'], training_data['spectral_mean'])\n",
    "    plt.title('Spectral Mean')\n",
    "    plt.subplot(4, 1, 4)\n",
    "    plt.plot(training_data['time_rel(sec)'], training_data['trigger'])\n",
    "    plt.title('Trigger On/Off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_data_plot.png')\n",
    "    plt.close()\n",
    "\n",
    "# Example usage\n",
    "catalog_path = './data/lunar/training/catalogs/apollo12_catalog_GradeA_final.csv'\n",
    "data_directory = './data/lunar/training/data'\n",
    "\n",
    "print(f\"Catalog path: {os.path.abspath(catalog_path)}\")\n",
    "print(f\"Data directory: {os.path.abspath(data_directory)}\")\n",
    "\n",
    "isolation_forest, scaler, arima_model, training_data = train_models(catalog_path, data_directory)\n",
    "\n",
    "if training_data is not None:\n",
    "    plot_training_data(training_data)\n",
    "    print(\"Training completed. Models are ready for use.\")\n",
    "\n",
    "    # Save models for later use\n",
    "    joblib.dump(isolation_forest, 'isolation_forest_model.joblib')\n",
    "    joblib.dump(scaler, 'scaler.joblib')\n",
    "    joblib.dump(arima_model, 'arima_model.joblib')\n",
    "else:\n",
    "    print(\"Training failed. Please check your data and file paths.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9d644ad-17eb-4fed-8787-91a5d96e6300",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'isolation_forest_model.joblib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjoblib\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Load models\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m isolation_forest \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124misolation_forest_model.joblib\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     11\u001b[0m scaler \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscaler.joblib\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     12\u001b[0m arima_model \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marima_model.joblib\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\project\\Lib\\site-packages\\joblib\\numpy_pickle.py:650\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, mmap_mode)\u001b[0m\n\u001b[0;32m    648\u001b[0m         obj \u001b[38;5;241m=\u001b[39m _unpickle(fobj)\n\u001b[0;32m    649\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    651\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m _read_fileobject(f, filename, mmap_mode) \u001b[38;5;28;01mas\u001b[39;00m fobj:\n\u001b[0;32m    652\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    653\u001b[0m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[0;32m    654\u001b[0m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[0;32m    655\u001b[0m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'isolation_forest_model.joblib'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load and preprocess test data\n",
    "def load_test_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    data['time_abs'] = pd.to_datetime(data['time_abs(%Y-%m-%dT%H:%M:%S.%f)'])\n",
    "    data['velocity'] = data['velocity(m/s)']\n",
    "    return data\n",
    "\n",
    "# Apply feature engineering to test data\n",
    "def engineer_test_features(data):\n",
    "    # Use the same feature engineering as in training\n",
    "    data['velocity_rolling_mean'] = data['velocity'].rolling(window=100).mean()\n",
    "    data['velocity_rolling_std'] = data['velocity'].rolling(window=100).std()\n",
    "    \n",
    "    f, t, Sxx = signal.spectrogram(data['velocity'], fs=1/(data['time_rel(sec)'].diff().mean()))\n",
    "    spectral_mean = np.mean(Sxx, axis=0)\n",
    "    spectral_std = np.std(Sxx, axis=0)\n",
    "    \n",
    "    data['spectral_mean'] = np.interp(data['time_rel(sec)'], t, spectral_mean)\n",
    "    data['spectral_std'] = np.interp(data['time_rel(sec)'], t, spectral_std)\n",
    "    \n",
    "    sta_window = 120\n",
    "    lta_window = 600\n",
    "    data['sta'] = data['velocity'].abs().rolling(window=sta_window).mean()\n",
    "    data['lta'] = data['velocity'].abs().rolling(window=lta_window).mean()\n",
    "    data['sta_lta_ratio'] = data['sta'] / data['lta']\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Detect anomalies using Isolation Forest\n",
    "def detect_anomalies(data, isolation_forest, scaler):\n",
    "    features = ['velocity', 'velocity_rolling_mean', 'velocity_rolling_std', 'spectral_mean', 'spectral_std', 'sta_lta_ratio']\n",
    "    X = data[features].dropna()\n",
    "    X_scaled = scaler.transform(X)\n",
    "    \n",
    "    anomalies = isolation_forest.predict(X_scaled)\n",
    "    data['is_anomaly'] = pd.Series(anomalies).replace({1: 0, -1: 1})\n",
    "    return data\n",
    "\n",
    "# Forecast using ARIMA\n",
    "def forecast_arima(data, arima_model):\n",
    "    forecast = arima_model.forecast(steps=len(data))\n",
    "    data['forecast'] = forecast\n",
    "    return data\n",
    "\n",
    "# Identify potential seismic events\n",
    "def identify_events(data, anomaly_threshold=0.8, forecast_threshold=2):\n",
    "    potential_events = data[\n",
    "        (data['is_anomaly'] == 1) & \n",
    "        (data['sta_lta_ratio'] > anomaly_threshold) & \n",
    "        (np.abs(data['velocity'] - data['forecast']) > forecast_threshold * data['velocity_rolling_std'])\n",
    "    ]\n",
    "    return potential_events\n",
    "\n",
    "# Main testing function\n",
    "def test_models(file_path, isolation_forest, scaler, arima_model):\n",
    "    test_data = load_test_data(file_path)\n",
    "    test_data = engineer_test_features(test_data)\n",
    "    \n",
    "    test_data = detect_anomalies(test_data, isolation_forest, scaler)\n",
    "    test_data = forecast_arima(test_data, arima_model)\n",
    "    \n",
    "    potential_events = identify_events(test_data)\n",
    "    \n",
    "    return test_data, potential_events\n",
    "\n",
    "# Example usage\n",
    "test_file_path = 'path/to/your/test_data.csv'\n",
    "test_data, potential_events = test_models(test_file_path, isolation_forest, scaler, arima_model)\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.plot(test_data['time_rel(sec)'], test_data['velocity'], label='Velocity')\n",
    "plt.plot(test_data['time_rel(sec)'], test_data['forecast'], label='ARIMA Forecast', alpha=0.7)\n",
    "plt.scatter(potential_events['time_rel(sec)'], potential_events['velocity'], color='red', label='Potential Events')\n",
    "plt.legend()\n",
    "plt.title('Test Data with Potential Seismic Events')\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Velocity (m/s)')\n",
    "plt.show()\n",
    "\n",
    "# Print potential event times\n",
    "print(\"Potential seismic event times:\")\n",
    "print(potential_events['time_abs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b8e1e2-4040-4005-9d75-ea18ff1f28cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load and preprocess test data\n",
    "def load_test_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    data['time_abs'] = pd.to_datetime(data['time_abs(%Y-%m-%dT%H:%M:%S.%f)'])\n",
    "    data['velocity'] = data['velocity(m/s)']\n",
    "    return data\n",
    "\n",
    "# Apply feature engineering to test data\n",
    "def engineer_test_features(data):\n",
    "    # Use the same feature engineering as in training\n",
    "    data['velocity_rolling_mean'] = data['velocity'].rolling(window=100).mean()\n",
    "    data['velocity_rolling_std'] = data['velocity'].rolling(window=100).std()\n",
    "    \n",
    "    f, t, Sxx = signal.spectrogram(data['velocity'], fs=1/(data['time_rel(sec)'].diff().mean()))\n",
    "    spectral_mean = np.mean(Sxx, axis=0)\n",
    "    spectral_std = np.std(Sxx, axis=0)\n",
    "    \n",
    "    data['spectral_mean'] = np.interp(data['time_rel(sec)'], t, spectral_mean)\n",
    "    data['spectral_std'] = np.interp(data['time_rel(sec)'], t, spectral_std)\n",
    "    \n",
    "    sta_window = 120\n",
    "    lta_window = 600\n",
    "    data['sta'] = data['velocity'].abs().rolling(window=sta_window).mean()\n",
    "    data['lta'] = data['velocity'].abs().rolling(window=lta_window).mean()\n",
    "    data['sta_lta_ratio'] = data['sta'] / data['lta']\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Detect anomalies using Isolation Forest\n",
    "def detect_anomalies(data, isolation_forest, scaler):\n",
    "    features = ['velocity', 'velocity_rolling_mean', 'velocity_rolling_std', 'spectral_mean', 'spectral_std', 'sta_lta_ratio']\n",
    "    X = data[features].dropna()\n",
    "    X_scaled = scaler.transform(X)\n",
    "    \n",
    "    anomalies = isolation_forest.predict(X_scaled)\n",
    "    data['is_anomaly'] = pd.Series(anomalies).replace({1: 0, -1: 1})\n",
    "    return data\n",
    "\n",
    "# Forecast using ARIMA\n",
    "def forecast_arima(data, arima_model):\n",
    "    forecast = arima_model.forecast(steps=len(data))\n",
    "    data['forecast'] = forecast\n",
    "    return data\n",
    "\n",
    "# Identify potential seismic events\n",
    "def identify_events(data, anomaly_threshold=0.8, forecast_threshold=2):\n",
    "    potential_events = data[\n",
    "        (data['is_anomaly'] == 1) & \n",
    "        (data['sta_lta_ratio'] > anomaly_threshold) & \n",
    "        (np.abs(data['velocity'] - data['forecast']) > forecast_threshold * data['velocity_rolling_std'])\n",
    "    ]\n",
    "    return potential_events\n",
    "\n",
    "# Main testing function\n",
    "def test_models(file_path, isolation_forest, scaler, arima_model):\n",
    "    test_data = load_test_data(file_path)\n",
    "    test_data = engineer_test_features(test_data)\n",
    "    \n",
    "    test_data = detect_anomalies(test_data, isolation_forest, scaler)\n",
    "    test_data = forecast_arima(test_data, arima_model)\n",
    "    \n",
    "    potential_events = identify_events(test_data)\n",
    "    \n",
    "    return test_data, potential_events\n",
    "\n",
    "# Example usage\n",
    "test_file_path = 'path/to/your/test_data.csv'\n",
    "test_data, potential_events = test_models(test_file_path, isolation_forest, scaler, arima_model)\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.plot(test_data['time_rel(sec)'], test_data['velocity'], label='Velocity')\n",
    "plt.plot(test_data['time_rel(sec)'], test_data['forecast'], label='ARIMA Forecast', alpha=0.7)\n",
    "plt.scatter(potential_events['time_rel(sec)'], potential_events['velocity'], color='red', label='Potential Events')\n",
    "plt.legend()\n",
    "plt.title('Test Data with Potential Seismic Events')\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Velocity (m/s)')\n",
    "plt.show()\n",
    "\n",
    "# Print potential event times\n",
    "print(\"Potential seismic event times:\")\n",
    "print(potential_events['time_abs'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
